{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e0984c",
   "metadata": {
    "papermill": {
     "duration": 0.00595,
     "end_time": "2025-04-19T20:20:08.030972",
     "exception": false,
     "start_time": "2025-04-19T20:20:08.025022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ğŸª¶ BujoNow: A Bullet Journal Companion Powered by Gemini\n",
    "\n",
    "**BujoNow** is an AI-powered journaling assistant that listens, reads, and sees â€” helping users to plan tasks to achieve their goals, record their thoughts, and reflect by journaling through text, audio, and image inputs. Built with Gemini and RAG (retrieval-augmented generation), this tool offers journaling through chatting, take in the journal, analyzes journal entries and returns insightful feedback on mental wellness. This is a Capstone Project as part of the 5-day Gen AI Intensive Course with Google. \n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ Key Features\n",
    "\n",
    "### 1. Journal Entry Analysis with Gemini + RAG\n",
    "\n",
    "Powered by Googleâ€™s **Gemini API**, this feature processes free-text journal entries and returns structured emotional insights:\n",
    "\n",
    "- **Record Journal from Chats**: You can plan and record your day while chatting\n",
    "- **Emotion Detection**: Identifies the userâ€™s dominant emotion  \n",
    "- **Theme Extraction**: Pulls out 2â€“3 key themes  \n",
    "- **CBT-style Suggestions**: Offers a reflection strategy inspired by Cognitive Behavioral Therapy  \n",
    "- **Affirmation Generation**: Provides a personalized daily affirmation  \n",
    "- **Context-Aware**: Uses **RAG** over curated mental wellness tips to ground responses\n",
    "\n",
    "> Example input:  \n",
    "> _â€œI feel overwhelmed and tired. I didnâ€™t get much done today.â€_\n",
    "\n",
    "> Example recorded Journal:\n",
    "\n",
    ">  =============================================\n",
    "> ## 2025-04-16 - Daily\n",
    "> This was a tiring day\n",
    "\n",
    "> ### Emotional State\n",
    "> {'emotion': 'tired', 'themes': ['fatigue', 'exhaustion'], 'suggestion': 'Reflect on what activities drained you today and consider strategies to manage your energy better.', 'affirmation': 'Itâ€™s okay to have bad days and ask for support when you need it.'}\n",
    "\n",
    "> ### Tags\n",
    "> tiring, self-care\n",
    "\n",
    "> =============================================\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Audio Transcription and Analysis\n",
    "\n",
    "Users can speak their journal entries via `.m4a` or `.wav` uploads. The tool will:\n",
    "\n",
    "- Transcribe speech using **Google Speech Recognition**\n",
    "- Automatically convert `.m4a` to `.wav` if needed\n",
    "- Pass the transcription into the journal analyzer pipeline\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Emotion Detection from Images\n",
    "\n",
    "Upload a photo of yourself, and the tool uses facial expression recognition to determine your likely mood:\n",
    "\n",
    "- Detects expressions like *happy*, *sad*, *angry*, *surprised*, etc.\n",
    "- Built using the **FER** (Facial Emotion Recognition) library and MTCNN face detection\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Mood Visualizations\n",
    "\n",
    "Turn journal entries into long-term insight with:\n",
    "\n",
    "#### Mood Trend Over Time\n",
    "A line graph of your emotional score over multiple days:\n",
    "- Maps moods into a 1â€“5 range (e.g., `hopeless = 1`, `grateful = 5`)\n",
    "- Highlights growth, stability, or downward spirals visually\n",
    "\n",
    "#### Emotion Distribution\n",
    "See what emotions dominate across entries:\n",
    "- Simple bar chart of emotion frequency\n",
    "- Great for identifying emotional patterns\n",
    "\n",
    "#### Word Cloud\n",
    "Explore the most common concepts in your journal entries:\n",
    "- Filters stopwords and stems for cleaner results\n",
    "- Visualizes top recurring topics from your reflections\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Setting Goals and Provide Tips\n",
    "\n",
    "#### Setting Goals\n",
    "By inputting your personal goals, provide AI-assited tips on how to achieving the goals.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Weekly Summary\n",
    "At the end of each week, BujoNow generates a summary of your emotional journey, highlighting the primary emotions and themes that emerged, as well as any actionable suggestions for improvement.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## AI Capabilities in BujoNow:\n",
    "### 1. Structured (JSON) Output\n",
    "Gemini 2.0 Flash: This version of Gemini generates structured JSON responses from journal text. The response includes emotional insights, themes, suggestions, and affirmations, providing a well-organized, consistent format for each journal entry's analysis.\n",
    "\n",
    "### 2. Sampling Control: \n",
    "To increase diversity in responses, BujoNow uses sampling techniques such as temperature (set to 0.8), top-p (nucleus sampling at 0.9), and top-k (50 tokens considered at each step). These settings introduce controlled randomness, ensuring varied yet coherent responses based on journal inputs. By adjusting these parameters, the system can provide more dynamic and diverse feedback, enriching the user experience with multiple perspectives.\n",
    "\n",
    "### 3. Retrieval Augmented Generation (RAG)\n",
    "Contextual Grounding: RAG is implemented by embedding mental health best practices and retrieving the most relevant advice based on the journal entry. The top-k most relevant contexts are fetched to guide the response.\n",
    "\n",
    "Functions Used: This process is facilitated through get_top_context(), embed_content(), and cosine similarity to find and retrieve the best matching context, ensuring personalized, context-driven feedback. The embeddings help score how closely journal entries align with mental health practices or themes, enhancing the quality and relevance of the feedback.\n",
    "\n",
    "### 4. Image Understanding\n",
    "Facial Emotion Recognition (FER): Using facenet-pytorch, BujoNow extracts emotional expressions from user-uploaded images, allowing it to assess emotions like happiness, sadness, or anger directly from facial expressions.\n",
    "\n",
    "### 5. Audio Understanding\n",
    "Speech Recognition: BujoNow supports voice journal entries via speech recognition with the recognize_google() function from the speech_recognition library, transcribing spoken input into text.\n",
    "\n",
    "Emotion & Content Analysis: After transcription, the text is analyzed for emotional content, and suggestions or insights are provided based on the emotional and thematic aspects of the audio journal entry.\n",
    "\n",
    "### 6. Few-Shot Prompting\n",
    "Prompt Design: The Gemini model is provided with few-shot examples that demonstrate how journal entries map to structured responses. This improves the model's ability to process and generate consistent feedback based on various journal input styles.\n",
    "\n",
    "### 7. Function Calls through Chatbot\n",
    "Interactive Chatbot: The chatbot can execute function calls to provide real-time feedback, analyze journal entries, and suggest actionable steps based on the emotional context. It integrates seamlessly with the user's mood-tracking experience, ensuring a conversational and personalized interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6f7b4",
   "metadata": {
    "papermill": {
     "duration": 0.004465,
     "end_time": "2025-04-19T20:20:08.040356",
     "exception": false,
     "start_time": "2025-04-19T20:20:08.035891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get started with Kaggle notebooks\n",
    "\n",
    "If this is your first time using a Kaggle notebook, welcome! You can read about how to use Kaggle notebooks [in the docs](https://www.kaggle.com/docs/notebooks).\n",
    "\n",
    "## Get started with the Gemini API\n",
    "\n",
    "All of the exercises in this notebook will use the [Gemini API](https://ai.google.dev/gemini-api/) by way of the [Python SDK](https://pypi.org/project/google-genai/). Each of these prompts can be accessed directly in [Google AI Studio](https://aistudio.google.com/) too, so if you would rather use a web interface and skip the code for this activity, look for the <img src=\"https://ai.google.dev/site-assets/images/marketing/home/icon-ais.png\" style=\"height: 24px\" height=24/> AI Studio link on each prompt.\n",
    "\n",
    "Next, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-media/Images/5dgai_1.png)\n",
    "![](https://storage.googleapis.com/kaggle-media/Images/5dgai_2.png)\n",
    "![](https://storage.googleapis.com/kaggle-media/Images/5dgai_3.png)\n",
    "![](https://storage.googleapis.com/kaggle-media/Images/5dgai_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1f443",
   "metadata": {
    "papermill": {
     "duration": 0.004433,
     "end_time": "2025-04-19T20:20:08.049427",
     "exception": false,
     "start_time": "2025-04-19T20:20:08.044994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing Requirements\n",
    "\n",
    "This may take few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397e2b1f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T20:20:08.060031Z",
     "iopub.status.busy": "2025-04-19T20:20:08.059672Z",
     "iopub.status.idle": "2025-04-19T20:23:54.528371Z",
     "shell.execute_reply": "2025-04-19T20:23:54.527610Z"
    },
    "papermill": {
     "duration": 226.475915,
     "end_time": "2025-04-19T20:23:54.529915",
     "exception": false,
     "start_time": "2025-04-19T20:20:08.054000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCollecting chromadb\r\n",
      "  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\r\n",
      "Collecting build>=1.0.3 (from chromadb)\r\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.3)\r\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\r\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\r\n",
      "Collecting fastapi==0.115.9 (from chromadb)\r\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\r\n",
      "Collecting posthog>=2.4.0 (from chromadb)\r\n",
      "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\r\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\r\n",
      "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\r\n",
      "Collecting pypika>=0.48.9 (from chromadb)\r\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\r\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\r\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\r\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\r\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\r\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\r\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\r\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\r\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\r\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\r\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\r\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\r\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\r\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\r\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\r\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\r\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\r\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\r\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\r\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\r\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\r\n",
      "Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\r\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\r\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\r\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\r\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\r\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\r\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\r\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\r\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=2e47c632e381fa4a8523114c7528390030df87dea6a609dc49f93496ec3ebfa0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\r\n",
      "Successfully built pypika\r\n",
      "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, opentelemetry-util-http, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, onnxruntime, chroma-hnswlib, chromadb\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: opentelemetry-api\r\n",
      "    Found existing installation: opentelemetry-api 1.16.0\r\n",
      "    Uninstalling opentelemetry-api-1.16.0:\r\n",
      "      Successfully uninstalled opentelemetry-api-1.16.0\r\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\r\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\r\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\r\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\r\n",
      "  Attempting uninstall: opentelemetry-sdk\r\n",
      "    Found existing installation: opentelemetry-sdk 1.16.0\r\n",
      "    Uninstalling opentelemetry-sdk-1.16.0:\r\n",
      "      Successfully uninstalled opentelemetry-sdk-1.16.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-3.25.0 protobuf-5.29.4 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\r\n",
      "Collecting gradio\r\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\r\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.9)\r\n",
      "Collecting ffmpy (from gradio)\r\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting gradio-client==1.8.0 (from gradio)\r\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting groovy~=0.1 (from gradio)\r\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\r\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\r\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\r\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\r\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\r\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\r\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\r\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\r\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\r\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\r\n",
      "Collecting ruff>=0.9.3 (from gradio)\r\n",
      "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\r\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting semantic-version~=2.0 (from gradio)\r\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\r\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\r\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\r\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\r\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\r\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\r\n",
      "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\r\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\r\n",
      "Installing collected packages: tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, safehttpx, gradio-client, gradio\r\n",
      "Successfully installed ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 tomlkit-0.13.2\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 122 not upgraded.\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gradio-calendar\r\n",
      "  Downloading gradio_calendar-0.0.6-py3-none-any.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: gradio<6.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio-calendar) (5.25.2)\r\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (22.1.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (4.9.0)\r\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.115.9)\r\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.5.0)\r\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (1.8.0)\r\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.1.2)\r\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.30.2)\r\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (3.1.6)\r\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (3.0.2)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (1.26.4)\r\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (3.10.15)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (24.2)\r\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (2.2.3)\r\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (10.2.0)\r\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (2.11.3)\r\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.25.1)\r\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.0.20)\r\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (6.0.2)\r\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.11.6)\r\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.1.6)\r\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (2.10.0)\r\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.45.3)\r\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.13.2)\r\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.15.1)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (4.13.1)\r\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio<6.0,>=4.0->gradio-calendar) (0.34.2)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio<6.0,>=4.0->gradio-calendar) (2025.3.2)\r\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio<6.0,>=4.0->gradio-calendar) (14.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<6.0,>=4.0->gradio-calendar) (3.10)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<6.0,>=4.0->gradio-calendar) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<6.0,>=4.0->gradio-calendar) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<6.0,>=4.0->gradio-calendar) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<6.0,>=4.0->gradio-calendar) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio<6.0,>=4.0->gradio-calendar) (3.18.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio<6.0,>=4.0->gradio-calendar) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio<6.0,>=4.0->gradio-calendar) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2025.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0,>=4.0->gradio-calendar) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0,>=4.0->gradio-calendar) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio<6.0,>=4.0->gradio-calendar) (0.4.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (14.0.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (2.19.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio<6.0,>=4.0->gradio-calendar) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio<6.0,>=4.0->gradio-calendar) (2.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio<6.0,>=4.0->gradio-calendar) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio-calendar) (0.1.2)\r\n",
      "Downloading gradio_calendar-0.0.6-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: gradio-calendar\r\n",
      "Successfully installed gradio-calendar-0.0.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-generativeai PyMuPDF\n",
    "!pip uninstall -qqy jupyterlab  \n",
    "!pip install -U -q \"google-genai==1.7.0\"\n",
    "!pip install chromadb\n",
    "!pip install gradio\n",
    "!pip install -q SpeechRecognition\n",
    "!pip install -q pydub\n",
    "!apt-get -y install ffmpeg\n",
    "!pip install -q fer\n",
    "!pip install -q mtcnn \n",
    "!pip install -q pillow\n",
    "!pip install -q facenet-pytorch\n",
    "!pip install gradio-calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce9504",
   "metadata": {
    "papermill": {
     "duration": 0.044685,
     "end_time": "2025-04-19T20:23:54.621028",
     "exception": false,
     "start_time": "2025-04-19T20:23:54.576343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Environment Configuration and DependenciesÂ¶\n",
    "This section establishes the foundational environment for our multimodal content analysis platform. We begin by configuring the Python environment and installing essential dependencies that enable various AI capabilities:\n",
    "\n",
    "- *Google Generative AI: Core library for accessing advanced language and vision models*\n",
    "- os: Operating system interactions for environment configuration.\n",
    "- tensorflow: Numerical computation and potential machine learning for text analysis.\n",
    "- google.genai: Generative AI models for text generation and potentially analysis.\n",
    "- google.genai.types: Type definitions for the Google Generative AI library.\n",
    "- kaggle_secrets: Securely access API keys in a Kaggle environment.\n",
    "- numpy: Numerical operations, especially for handling text embeddings.\n",
    "- re: Regular expressions for text pattern matching and manipulation.\n",
    "- sklearn.metrics.pairwise.cosine_similarity: Calculate text similarity for analysis.\n",
    "- nltk.corpus.stopwords: Collection of common words for text filtering.\n",
    "- nltk.stem.PorterStemmer: Algorithm for reducing words to their root form.\n",
    "- nltk: Natural Language Toolkit for various text processing tasks.\n",
    "- gradio: Library for creating the user interface of the assistant.\n",
    "- json: Handling JSON data for storage and configuration.\n",
    "- matplotlib.pyplot: Plotting library for visualizing data from journal entries.\n",
    "- datetime: Handling dates and times for organizing and analyzing entries.\n",
    "- typing: Type hinting for improved code readability and maintainability.\n",
    "- speech_recognition: Converting spoken audio into text for voice journaling.\n",
    "- PIL (Pillow): Image processing capabilities for handling images in entries.\n",
    "- typing_extensions: Backports of newer typing features.\n",
    "- collections.Counter: Counting word frequencies for analysis.\n",
    "- pydub: Audio file manipulation for voice entries.\n",
    "- string: Collection of string constants for text processing.\n",
    "- gradio_calendar: Custom Gradio component for date selection.\n",
    "- PIL._util: Internal Pillow module (likely for a workaround).\n",
    "- wordcloud: Generating visual representations of word frequencies.\n",
    "- facenet_pytorch.MTCNN: Detecting faces in images within journal entries.\n",
    "- fer: Facial Emotion Recognition from images in journal entries.\n",
    "\n",
    "The selection of these specific packages was driven by their proven reliability in production environments and their ability to work seamlessly together in a multimodal context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be04e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:23:54.781356Z",
     "iopub.status.busy": "2025-04-19T20:23:54.780522Z",
     "iopub.status.idle": "2025-04-19T20:24:20.993584Z",
     "shell.execute_reply": "2025-04-19T20:24:20.992189Z"
    },
    "papermill": {
     "duration": 26.266586,
     "end_time": "2025-04-19T20:24:20.995306",
     "exception": false,
     "start_time": "2025-04-19T20:23:54.728720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745094236.368368      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745094236.424816      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Check if XDG_RUNTIME_DIR is set\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))  # Should be []\n",
    "if 'XDG_RUNTIME_DIR' not in os.environ:\n",
    "    os.environ['XDG_RUNTIME_DIR'] = '/tmp/runtime-user'\n",
    "# print(\"XDG_RUNTIME_DIR set to:\", os.environ['XDG_RUNTIME_DIR'])\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import gradio as gr\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import List, Dict\n",
    "import speech_recognition as sr\n",
    "from PIL import Image\n",
    "import typing_extensions as typing\n",
    "from collections import Counter\n",
    "from pydub import AudioSegment\n",
    "import string\n",
    "from datetime import datetime\n",
    "from gradio_calendar import Calendar\n",
    "import PIL._util\n",
    "PIL._util.is_directory = lambda x: False  \n",
    "from wordcloud import WordCloud\n",
    "from facenet_pytorch import MTCNN\n",
    "mtcnn = MTCNN()\n",
    "from fer import FER\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03570c2",
   "metadata": {
    "papermill": {
     "duration": 0.046779,
     "end_time": "2025-04-19T20:24:21.091150",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.044371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Google API Key\n",
    "Make sure you've followed \"Get started with the Gemini API\" part that sets the **GOOGLE_API_KEY** in the Add-ons before running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157ef34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:21.194107Z",
     "iopub.status.busy": "2025-04-19T20:24:21.193373Z",
     "iopub.status.idle": "2025-04-19T20:24:21.467938Z",
     "shell.execute_reply": "2025-04-19T20:24:21.467072Z"
    },
    "papermill": {
     "duration": 0.331636,
     "end_time": "2025-04-19T20:24:21.469787",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.138151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API Setup \n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df423b4",
   "metadata": {
    "papermill": {
     "duration": 0.049334,
     "end_time": "2025-04-19T20:24:21.575185",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.525851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Add RAG Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bd055f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:21.671586Z",
     "iopub.status.busy": "2025-04-19T20:24:21.671193Z",
     "iopub.status.idle": "2025-04-19T20:24:21.679196Z",
     "shell.execute_reply": "2025-04-19T20:24:21.678537Z"
    },
    "papermill": {
     "duration": 0.056805,
     "end_time": "2025-04-19T20:24:21.680471",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.623666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- RAG Documents -----------------------------\n",
    "RAG_DOCUMENTS = [\n",
    "    \"Practicing gratitude can significantly improve mental well-being by shifting focus from negative thoughts.\",\n",
    "    \"CBT techniques help reframe negative thinking patterns into constructive insights.\",\n",
    "    \"Social connection and being heard improve emotional regulation and resilience.\",\n",
    "    \"Journaling builds self-awareness and emotional processing.\",\n",
    "    \"Mindfulness and breathing exercises can reduce anxiety symptoms.\",\n",
    "    \"Setting boundaries helps prevent burnout and protects well-being.\",\n",
    "    \"Labeling emotions accurately helps regulate them.\",\n",
    "    \"Acts of self-care can boost mood and positivity.\",\n",
    "    \"A sense of purpose improves long-term well-being.\",\n",
    "    \"Self-compassion reduces self-criticism and nurtures kindness.\",\n",
    "    \"Building resilience involves embracing challenges and learning from adversity.\",\n",
    "    \"Exercise and physical activity have a profound impact on mental health.\",\n",
    "    \"Developing a growth mindset helps overcome obstacles and setbacks.\",\n",
    "    \"Sleep hygiene and quality rest play a critical role in emotional health.\",\n",
    "    \"Accepting imperfections and practicing self-forgiveness can reduce stress.\",\n",
    "    \"Positive affirmations can improve self-esteem and mental clarity.\",\n",
    "    \"Mindful eating and nutrition impact mental and emotional states.\",\n",
    "    \"Visualization techniques can help manage stress and anxiety.\",\n",
    "    \"Effective communication skills are essential for managing conflict and building connections.\",\n",
    "    \"Grief is a complex emotional experience that requires time, patience, and support.\",\n",
    "    \"Your mental health is just as important as your physical health.\",\n",
    "    \"Itâ€™s okay not to be okay.\",\n",
    "    \"You are not your mental illness.\",\n",
    "    \"Your struggles do not define you.\",\n",
    "    \"Taking care of your mental health is an act of self-love.\",\n",
    "    \"You are worthy of happiness and peace of mind.\",\n",
    "    \"There is no shame in seeking help for your mental health.\",\n",
    "    \"Itâ€™s okay to take a break and prioritize your mental health.\",\n",
    "    \"You are not alone in your struggles.\",\n",
    "    \"Itâ€™s okay to ask for support when you need it.\",\n",
    "    \"Mental health is not a destination, itâ€™s a journey.\",\n",
    "    \"Your mental health matters more than any external validation.\",\n",
    "    \"You are stronger than you realize.\",\n",
    "    \"Self-care is not selfish, itâ€™s necessary for good mental health.\",\n",
    "    \"Small steps can lead to big progress in mental health.\",\n",
    "    \"You are capable of overcoming your mental health challenges.\",\n",
    "    \"Mental illness is not a personal failure, itâ€™s a medical condition.\",\n",
    "    \"You are deserving of a life free from mental health struggles.\",\n",
    "    \"Itâ€™s okay to take medication for your mental health.\",\n",
    "    \"You are not a burden for seeking help for your mental health.\",\n",
    "    \"Mental health issues do not make you any less of a person.\",\n",
    "    \"Your mental health is just as important as your career or education.\",\n",
    "    \"You are capable of managing your mental health and living a fulfilling life.\",\n",
    "    \"You have the power to overcome your mental health challenges.\",\n",
    "    \"You are deserving of love and compassion, especially from yourself.\",\n",
    "    \"Your mental health struggles do not define your future.\",\n",
    "    \"Itâ€™s okay to prioritize your mental health over other commitments.\",\n",
    "    \"You are not alone in your journey towards better mental health.\",\n",
    "    \"Mental health recovery is possible, and it starts with seeking help.\",\n",
    "    \"You are worthy of a life filled with joy and happiness.\",\n",
    "    \"Itâ€™s okay to have bad days and ask for support when you need it.\",\n",
    "    \"You have the power to change your relationship with your mental health.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9775e6",
   "metadata": {
    "papermill": {
     "duration": 0.046584,
     "end_time": "2025-04-19T20:24:21.774595",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.728011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use text-embedding model to add RAG documents as contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0b1acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:21.869860Z",
     "iopub.status.busy": "2025-04-19T20:24:21.869179Z",
     "iopub.status.idle": "2025-04-19T20:24:23.031378Z",
     "shell.execute_reply": "2025-04-19T20:24:23.030502Z"
    },
    "papermill": {
     "duration": 1.211251,
     "end_time": "2025-04-19T20:24:23.033041",
     "exception": false,
     "start_time": "2025-04-19T20:24:21.821790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- Embed RAG Documents -----------------------------\n",
    "embedding_response = client.models.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    contents=RAG_DOCUMENTS,\n",
    "    config=types.EmbedContentConfig(task_type=\"retrieval_document\")\n",
    ")\n",
    "rag_embeddings = [e.values for e in embedding_response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338d5a3",
   "metadata": {
    "papermill": {
     "duration": 0.046832,
     "end_time": "2025-04-19T20:24:23.127728",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.080896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a Journal Manager\n",
    "Create a Journal Manager class to manage the journal entries. Whenever the user is inputting an entry, the journal manager will save it to local files in JSON format. And the manager will also be helpful for retrieving the content from the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89849949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:23.220083Z",
     "iopub.status.busy": "2025-04-19T20:24:23.219791Z",
     "iopub.status.idle": "2025-04-19T20:24:23.242066Z",
     "shell.execute_reply": "2025-04-19T20:24:23.241273Z"
    },
    "papermill": {
     "duration": 0.069795,
     "end_time": "2025-04-19T20:24:23.243418",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.173623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Journal Manager\n",
    "Handles creating, saving, and managing journal entries with bullet journal features.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "class JournalManager:\n",
    "    def __init__(self, journal_dir: str = \"journals\"):\n",
    "        \"\"\"Initialize the journal manager\"\"\"\n",
    "        self.journal_dir = journal_dir\n",
    "        self._ensure_journal_dir()\n",
    "\n",
    "    def _ensure_journal_dir(self):\n",
    "        \"\"\"Ensure the journal directory exists\"\"\"\n",
    "        Path(self.journal_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _get_journal_path(self, date: datetime) -> str:\n",
    "        \"\"\"Get the path for a journal file based on date\"\"\"\n",
    "        return os.path.join(self.journal_dir, f\"{date.strftime('%Y-%m')}\", f\"{date.strftime('%Y-%m-%d')}.json\")\n",
    "\n",
    "    def create_entry(self, \n",
    "                    text: str, \n",
    "                    emotion_analysis: Dict,\n",
    "                    date: Optional[datetime] = None,\n",
    "                    tasks: List[Dict] = None,\n",
    "                    goals: List[Dict] = None,\n",
    "                    tags: List[str] = None,\n",
    "                    category: str = \"daily\") -> Dict:\n",
    "        \"\"\"\n",
    "        Create a new journal entry\n",
    "        \n",
    "        Args:\n",
    "            text: The main journal text\n",
    "            emotion_analysis: Dict containing emotion analysis {\n",
    "                \"primary_emotion\": str,\n",
    "                \"emotion_intensity\": int (1-10),\n",
    "                \"emotional_themes\": List[str],\n",
    "                \"mood_summary\": str,\n",
    "                \"suggested_actions\": List[str]\n",
    "            }\n",
    "            date: Entry date (defaults to now)\n",
    "            tasks: List of tasks [{\"task\": \"task text\", \"status\": \"pending/done\", \"priority\": \"high/medium/low\"}]\n",
    "            goals: List of goals [{\"goal\": \"goal text\", \"timeframe\": \"daily/weekly/monthly\", \"progress\": 0-100}]\n",
    "            tags: List of tags for the entry\n",
    "            category: Entry category (daily, weekly, monthly, etc.)\n",
    "        \"\"\"\n",
    "        if date is None:\n",
    "            date = datetime.now()\n",
    "\n",
    "        # Create entry structure\n",
    "        entry = {\n",
    "            \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"category\": category,\n",
    "            \"content\": {\n",
    "                \"text\": text,\n",
    "                \"tasks\": tasks or [],\n",
    "                \"goals\": goals or [],\n",
    "                \"tags\": tags or []\n",
    "            },\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"metadata\": {\n",
    "                \"last_modified\": datetime.now().isoformat(),\n",
    "                \"word_count\": len(text.split()),\n",
    "                \"has_tasks\": bool(tasks),\n",
    "                \"has_goals\": bool(goals)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Save the entry\n",
    "        self._save_entry(entry, date)\n",
    "        return entry\n",
    "\n",
    "    def _save_entry(self, entry: Dict, date: datetime):\n",
    "        \"\"\"Save a journal entry to file\"\"\"\n",
    "        file_path = self._get_journal_path(date)\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        \n",
    "        # Save the entry\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(entry, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    def get_entry(self, date: datetime) -> Optional[Dict]:\n",
    "        \"\"\"Retrieve a journal entry for a specific date\"\"\"\n",
    "        file_path = self._get_journal_path(date)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def update_entry(self, \n",
    "                    date: datetime,\n",
    "                    text: Optional[str] = None,\n",
    "                    emotion_analysis: Optional[Dict] = None,\n",
    "                    tasks: Optional[List[Dict]] = None,\n",
    "                    goals: Optional[List[Dict]] = None,\n",
    "                    tags: Optional[List[str]] = None) -> Optional[Dict]:\n",
    "        \"\"\"Update an existing journal entry\"\"\"\n",
    "        entry = self.get_entry(date)\n",
    "        if not entry:\n",
    "            return None\n",
    "\n",
    "        if text:\n",
    "            entry['content']['text'] = text\n",
    "            entry['metadata']['word_count'] = len(text.split())\n",
    "\n",
    "        if emotion_analysis:\n",
    "            entry['emotion_analysis'] = emotion_analysis\n",
    "\n",
    "        if tasks is not None:\n",
    "            entry['content']['tasks'] = tasks\n",
    "            entry['metadata']['has_tasks'] = bool(tasks)\n",
    "\n",
    "        if goals is not None:\n",
    "            entry['content']['goals'] = goals\n",
    "            entry['metadata']['has_goals'] = bool(goals)\n",
    "\n",
    "        if tags is not None:\n",
    "            entry['content']['tags'] = tags\n",
    "\n",
    "        entry['metadata']['last_modified'] = datetime.now().isoformat()\n",
    "        \n",
    "        self._save_entry(entry, date)\n",
    "        return entry\n",
    "\n",
    "    def search_entries(self, \n",
    "                      start_date: Optional[datetime] = None,\n",
    "                      end_date: Optional[datetime] = None,\n",
    "                      tags: Optional[List[str]] = None,\n",
    "                      emotion: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Search journal entries based on criteria\"\"\"\n",
    "        entries = []\n",
    "        \n",
    "        # If no dates specified, use the current month\n",
    "        if not start_date:\n",
    "            start_date = datetime.now().replace(day=1)\n",
    "        if not end_date:\n",
    "            end_date = datetime.now()\n",
    "\n",
    "        # Walk through the journal directory\n",
    "        for root, _, files in os.walk(self.journal_dir):\n",
    "            for file in files:\n",
    "                if not file.endswith('.json'):\n",
    "                    continue\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        entry = json.load(f)\n",
    "                        \n",
    "                    entry_date = datetime.strptime(entry['date'], '%Y-%m-%d')\n",
    "                    \n",
    "                    # Check if entry matches criteria\n",
    "                    if start_date <= entry_date <= end_date:\n",
    "                        if tags and not any(tag in entry['content']['tags'] for tag in tags):\n",
    "                            continue\n",
    "                        if emotion and entry['emotion_analysis']['primary_emotion'].lower() != emotion.lower():\n",
    "                            continue\n",
    "                        entries.append(entry)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading entry {file_path}: {str(e)}\")\n",
    "\n",
    "        return sorted(entries, key=lambda x: x['date']) \n",
    "\n",
    "    def get_all_entries(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve all journal entries in chronological order.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: A list of all journal entries sorted by date\n",
    "        \"\"\"\n",
    "        entries = []\n",
    "        \n",
    "        # Walk through the journal directory\n",
    "        for root, _, files in os.walk(self.journal_dir):\n",
    "            for file in files:\n",
    "                if not file.endswith('.json'):\n",
    "                    continue\n",
    "                \n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        entry = json.load(f)\n",
    "                        entries.append(entry)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading entry {file_path}: {str(e)}\")\n",
    "\n",
    "        # Sort entries by date\n",
    "        return sorted(entries, key=lambda x: x['date']) \n",
    "\n",
    "    def record_entry(self, \n",
    "                    text: str, \n",
    "                    emotion_analysis: Optional[Dict] = {},\n",
    "                    date: Optional[datetime] = datetime.now(),\n",
    "                    tasks: List[Dict] = [],\n",
    "                    goals: List[Dict] = [],\n",
    "                    tags: List[str] = [],\n",
    "                    category: str = \"daily\") -> Dict:\n",
    "        \"\"\"\n",
    "        Create a new entry if there were no entry on that day, and update the entry if there was prior entries created before.\n",
    "        \n",
    "        Args:\n",
    "            text: The main journal text\n",
    "            emotion_analysis: Dict containing emotion analysis {\n",
    "                \"primary_emotion\": str,\n",
    "                \"emotion_intensity\": int (1-10),\n",
    "                \"emotional_themes\": List[str],\n",
    "                \"mood_summary\": str,\n",
    "                \"suggested_actions\": List[str]\n",
    "            }\n",
    "            date: Entry date (defaults to now)\n",
    "            tasks: List of tasks [{\"task\": \"task text\", \"status\": \"pending/done\", \"priority\": \"high/medium/low\"}]\n",
    "            goals: List of goals [{\"goal\": \"goal text\", \"timeframe\": \"daily/weekly/monthly\", \"progress\": 0-100}]\n",
    "            tags: List of tags for the entry\n",
    "            category: Entry category (daily, weekly, monthly, etc.)\n",
    "        \"\"\"\n",
    "        entry = self.get_entry(date)\n",
    "        if not entry:\n",
    "            created_entry = self.create_entry(\n",
    "                text=text,\n",
    "                emotion_analysis=emotion_analysis,\n",
    "                date=date,\n",
    "                tasks=tasks,\n",
    "                goals=goals,\n",
    "                tags=tags,\n",
    "                category=category\n",
    "            )\n",
    "            return created_entry\n",
    "        else:\n",
    "            updated_emotion_analysis = emotion_analysis.update(entry[\"emotion_analysis\"])\n",
    "            # print(entry)\n",
    "            updated_entry = self.update_entry( \n",
    "                date=date,\n",
    "                text=text.replace(\"\\n\",\"\\\\n\").replace('[', '').replace(']', '') + \" \\n \" + entry['content']['text'],\n",
    "                emotion_analysis=updated_emotion_analysis,\n",
    "                tasks=tasks + entry['content'][\"tasks\"],\n",
    "                goals=goals + entry['content'][\"goals\"],\n",
    "                tags=tags + entry['content'][\"tags\"]\n",
    "            )\n",
    "            return updated_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c9ee0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:23.337679Z",
     "iopub.status.busy": "2025-04-19T20:24:23.336893Z",
     "iopub.status.idle": "2025-04-19T20:24:23.340928Z",
     "shell.execute_reply": "2025-04-19T20:24:23.340290Z"
    },
    "papermill": {
     "duration": 0.051911,
     "end_time": "2025-04-19T20:24:23.342051",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.290140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "journal_manager = JournalManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cd786",
   "metadata": {
    "papermill": {
     "duration": 0.045441,
     "end_time": "2025-04-19T20:24:23.433491",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.388050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze input text Journal \n",
    "\n",
    "Firstly, get the top matching RAG documents for an input text and return the concatenated top-k RAG documents.\n",
    "\n",
    "Parameters for getting top context (get_top_context):\n",
    "- input_text (str): The user journal text to match against RAG documents.\n",
    "- top_k (int): Number of top documents to retrieve.\n",
    "\n",
    "Then, use the selected top documents to help analyze the input journal.\n",
    "\n",
    "Parameters for analyze the journal inputted text (analyze_journal_entry):\n",
    "- input_text (str): The user's journal text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5692d61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:23.525412Z",
     "iopub.status.busy": "2025-04-19T20:24:23.524682Z",
     "iopub.status.idle": "2025-04-19T20:24:23.531876Z",
     "shell.execute_reply": "2025-04-19T20:24:23.531350Z"
    },
    "papermill": {
     "duration": 0.054931,
     "end_time": "2025-04-19T20:24:23.533051",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.478120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- Journal Analysis -----------------------------\n",
    "def get_top_context(input_text: str, top_k=3) -> str:\n",
    "    query_embedding = client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents=input_text,\n",
    "        config=types.EmbedContentConfig(task_type=\"retrieval_query\")\n",
    "    ).embeddings[0].values\n",
    "\n",
    "    scores = cosine_similarity([query_embedding], rag_embeddings)[0]\n",
    "    # print(f\"scores: {scores}\")\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    # print(f\"top_indices: {top_indices}\")\n",
    "    return \"\\n\".join([RAG_DOCUMENTS[i] for i in top_indices])\n",
    "\n",
    "class JournalAnalysis(typing.TypedDict):\n",
    "    emotion: str\n",
    "    themes: List[str]\n",
    "    suggestion: str\n",
    "    affirmation: str\n",
    "    \n",
    "def analyze_journal_entry(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes a journal entry using the Gemini model and returns a structured output\n",
    "    with emotion, themes, suggestions, and affirmation.\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): The user's journal text.\n",
    "    \n",
    "    Returns:\n",
    "        str: Parsed JSON response as a dictionary.\n",
    "    \"\"\"\n",
    "    context = get_top_context(input_text)\n",
    "    prompt = f\"\"\"\n",
    "        You are a supportive AI journaling assistant.\n",
    "        Analyze the user's journal input text and return a structured JSON with the following:\n",
    "        1. Primary emotion (e.g., sad, anxious, hopeful)\n",
    "        2. Up to 3 key themes\n",
    "        3. One CBT-style reflection suggestion\n",
    "        4. One daily affirmation\n",
    "\n",
    "        Use this context to ground your suggestions:\n",
    "        {context}\n",
    "\n",
    "        Here are a few examples:\n",
    "\n",
    "        Journal Input Text:\n",
    "        I feel hopeless. Everything I do seems to go wrong.\n",
    "        Response:\n",
    "        {{\n",
    "          \"emotion\": \"hopeless\",\n",
    "          \"themes\": [\"self-doubt\", \"negativity\"],\n",
    "          \"suggestion\": \"Try writing down three things that went well each day, no matter how small.\",\n",
    "          \"affirmation\": \"You are resilient and capable of overcoming hard days.\"\n",
    "        }}\n",
    "\n",
    "        Journal Input Text:\n",
    "        I felt better today. I went for a walk and saw some friends.\n",
    "        Response:\n",
    "        {{\n",
    "          \"emotion\": \"grateful\",\n",
    "          \"themes\": [\"connection\", \"nature\"],\n",
    "          \"suggestion\": \"Continue spending time doing things that bring you joy.\",\n",
    "          \"affirmation\": \"Joy is found in small, simple moments.\"\n",
    "        }}\n",
    "\n",
    "        Now analyze the following entry:\n",
    "        {input_text}\n",
    "        Respond in JSON format like:\n",
    "        {{\n",
    "          \"emotion\": \"...\",\n",
    "          \"themes\": [\"...\", \"...\"],\n",
    "          \"suggestion\": \"...\",\n",
    "          \"affirmation\": \"...\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        temperature=2,   # Increased to encourage more randomness\n",
    "        top_k=5,         # Number of top tokens to consider at each step\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=JournalAnalysis\n",
    "    )\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt],\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    return response.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee6362",
   "metadata": {
    "papermill": {
     "duration": 0.04521,
     "end_time": "2025-04-19T20:24:23.623962",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.578752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze Audio Input\n",
    "The following function receive the audio inputs from the user and make analysis of their emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a715433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:23.716377Z",
     "iopub.status.busy": "2025-04-19T20:24:23.715601Z",
     "iopub.status.idle": "2025-04-19T20:24:23.721282Z",
     "shell.execute_reply": "2025-04-19T20:24:23.720551Z"
    },
    "papermill": {
     "duration": 0.053053,
     "end_time": "2025-04-19T20:24:23.722414",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.669361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- Audio Processing -----------------------------\n",
    "def convert_m4a_to_wav(input_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts an M4A audio file to WAV format for processing.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input M4A audio file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the converted WAV file.\n",
    "    \"\"\"\n",
    "    output_path = input_path.rsplit(\".\", 1)[0] + \".wav\"\n",
    "    sound = AudioSegment.from_file(input_path, format=\"m4a\")\n",
    "    sound.export(output_path, format=\"wav\")\n",
    "    return output_path\n",
    "\n",
    "def recognize_audio(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes spoken audio to text using Google's Speech Recognition API.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to the WAV audio file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Transcribed text or error message.\n",
    "    \"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    try:\n",
    "        if audio_path.endswith(\".m4a\"):\n",
    "            audio_path = convert_m4a_to_wav(audio_path)\n",
    "\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        return recognizer.recognize_google(audio)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"[Transcription error] {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaaeda",
   "metadata": {
    "papermill": {
     "duration": 0.045584,
     "end_time": "2025-04-19T20:24:23.813392",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.767808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze Image Input\n",
    "This part of the function make analysis of the impage input from the user and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd95ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:23.906560Z",
     "iopub.status.busy": "2025-04-19T20:24:23.905805Z",
     "iopub.status.idle": "2025-04-19T20:24:23.910517Z",
     "shell.execute_reply": "2025-04-19T20:24:23.909967Z"
    },
    "papermill": {
     "duration": 0.052583,
     "end_time": "2025-04-19T20:24:23.911711",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.859128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- Image Analysis -----------------------------\n",
    "def detect_emotion_from_image(img: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Detects the dominant emotion in a facial image using the FER library.\n",
    "    \n",
    "    Args:\n",
    "        img (Image.Image): A PIL image containing a human face.\n",
    "    \n",
    "    Returns:\n",
    "        str: The top detected emotion or a message if no face is found.\n",
    "    \"\"\"\n",
    "    detector = FER(mtcnn=True)\n",
    "    img_array = np.array(img)\n",
    "    result = detector.detect_emotions(img_array)\n",
    "    if not result:\n",
    "        return \"unknown\"\n",
    "    emotions = result[0][\"emotions\"]\n",
    "    top_emotion = max(emotions, key=emotions.get)\n",
    "    return top_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30be61",
   "metadata": {
    "papermill": {
     "duration": 0.045259,
     "end_time": "2025-04-19T20:24:24.004291",
     "exception": false,
     "start_time": "2025-04-19T20:24:23.959032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac46b57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:24.096791Z",
     "iopub.status.busy": "2025-04-19T20:24:24.096238Z",
     "iopub.status.idle": "2025-04-19T20:24:24.154897Z",
     "shell.execute_reply": "2025-04-19T20:24:24.154097Z"
    },
    "papermill": {
     "duration": 0.106759,
     "end_time": "2025-04-19T20:24:24.156177",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.049418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# ----------------------------- Visualizations -----------------------------\n",
    "def get_emotion_score(emotion: str) -> int:\n",
    "    \"\"\"\n",
    "    Maps an emotion string to a numerical score for trend visualization.\n",
    "    \n",
    "    Args:\n",
    "        emotion (str): Emotion label (e.g., 'happy', 'sad').\n",
    "    \n",
    "    Returns:\n",
    "        int: A numerical score from 1 (low mood) to 5 (high mood).\n",
    "    \"\"\"\n",
    "    emotion = emotion.lower().strip()\n",
    "    \n",
    "    mood_categories = {\n",
    "        1: [\"burnt\", \"overwhelmed\", \"depressed\", \"hopeless\", \"terrible\", \"exhausted\", \"down\"],\n",
    "        2: [\"anxious\", \"sad\", \"stressed\", \"nervous\", \"worried\"],\n",
    "        3: [\"neutral\", \"okay\", \"fine\", \"meh\", \"uncertain\", \"tired\"],\n",
    "        4: [\"hopeful\", \"better\", \"relieved\", \"good\"],\n",
    "        5: [\"grateful\", \"happy\", \"calm\", \"joyful\", \"peaceful\", \"excited\"]\n",
    "    }\n",
    "\n",
    "    for score, keywords in mood_categories.items():\n",
    "        if any(re.search(rf\"\\b{kw}\\b\", emotion) for kw in keywords):\n",
    "            return score\n",
    "\n",
    "    return 3  # Default to neutral if no match\n",
    "    \n",
    "def plot_emotional_trend(results: List[Dict]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots a line chart of emotional scores over time based on journal entries.\n",
    "    \n",
    "    Args:\n",
    "        results (List[Dict]): List of journal entries with 'date' and 'emotion'.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: A plot showing mood trends.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return None\n",
    "\n",
    "    dates = [entry[\"date\"] for entry in results]\n",
    "    scores = [get_emotion_score(entry[\"emotion\"]) for entry in results]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(dates, scores, marker='o')\n",
    "    plt.title(\"Mood Trend Over Time (All Entry Types)\")\n",
    "    plt.ylabel(\"Emotional State (1=Low, 5=High)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks([1, 2, 3, 4, 5], [\"Very Low\", \"Low\", \"Neutral\", \"High\", \"Very High\"])\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_trend_wrapper():\n",
    "    \"\"\"\n",
    "    Wrapper function to plot journal trend chart from global variable journal_entries.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Trend plot figure.\n",
    "    \"\"\"\n",
    "    return plot_emotional_trend(journal_entries)\n",
    "    \n",
    "def plot_emotion_distribution(entries: List[Dict]):\n",
    "    \"\"\"\n",
    "    Generates a bar chart showing the distribution of different emotions across entries.\n",
    "    \n",
    "    Args:\n",
    "        entries (List[Dict]): List of journal entries with 'emotion'.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: A bar chart of emotion counts.\n",
    "    \"\"\"\n",
    "    emotion_counts = Counter(entry[\"emotion\"] for entry in entries if entry.get(\"emotion\"))\n",
    "    labels, values = zip(*emotion_counts.items())\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, values)\n",
    "    plt.title(\"Emotion Distribution\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "nltk.download('stopwords')\n",
    "def plot_wordcloud(entries: List[Dict]):\n",
    "    \"\"\"\n",
    "    Generates a word cloud visualization from all journal entry texts.\n",
    "    \n",
    "    Args:\n",
    "        entries (List[Dict]): List of journal entries with 'entry' text.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Word cloud plot.\n",
    "    \"\"\"\n",
    "    text = \" \".join(entry[\"entry\"] for entry in entries if entry.get(\"entry\"))\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered = [stemmer.stem(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    cleaned_text = \" \".join(filtered)\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white'\n",
    "    ).generate(cleaned_text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Common Words in Journal Entries\")\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "def reflect_on_week(entries: List[Dict]):\n",
    "    \"\"\"\n",
    "    Summarizes a user's journal entries from the past week and offers supportive advice.\n",
    "\n",
    "    Args:\n",
    "        entries (List[Dict]): A list of journal entries, each containing 'date', 'entry', and 'emotion'.\n",
    "\n",
    "    Returns:\n",
    "        str: A short reflection generated by Gemini summarizing the week's entries and advice.\n",
    "    \"\"\"\n",
    "    if not entries:\n",
    "        return \"No entries yet.\"\n",
    "    journal_texts = \"\\n\\n\".join(f\"{e['date']}: {e['entry']} ({e['emotion']})\" for e in entries[-7:])\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following journal logs from the past week and give the user some supportive advice:\n",
    "    {journal_texts}\n",
    "    Respond in a paragraph.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt]\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def suggest_tip_toward_goal(goal: str):\n",
    "    \"\"\"\n",
    "    Generates a CBT-style tip and affirmation to support progress toward a specific emotional goal.\n",
    "\n",
    "    Args:\n",
    "        goal (str): The desired emotional state, e.g., \"calm\", \"confident\".\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted suggestion with both a CBT tip and an affirmation.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Suggest a CBT-style action and affirmation to help someone feel more {goal}.\n",
    "    Format:\n",
    "    - Tip: ...\n",
    "    - Affirmation: ...\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt],\n",
    "        config=types.GenerateContentConfig(temperature=0.7)\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a24893",
   "metadata": {
    "papermill": {
     "duration": 0.045633,
     "end_time": "2025-04-19T20:24:24.248907",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.203274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup Chatbox\n",
    "1. summarize_week()\n",
    "2. suggest_cbt_tip\n",
    "3. describe_emotion_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b37629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:24.341465Z",
     "iopub.status.busy": "2025-04-19T20:24:24.340726Z",
     "iopub.status.idle": "2025-04-19T20:24:24.349326Z",
     "shell.execute_reply": "2025-04-19T20:24:24.348814Z"
    },
    "papermill": {
     "duration": 0.056453,
     "end_time": "2025-04-19T20:24:24.350426",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.293973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"You are a encouraging and helpful assistant that helps users to journal by conversation and record their thoughts in their mind. \\\n",
    "You care about their emotional status and will ask about how they are doing and if the users want to record any thoughts.\\\n",
    "You will frequently adding some encouraging words according to the user's input. \\\n",
    "When the user is talking about any tasks they want to complete, you will help them to break down their tasks to smaller portion and propose a proper timeline.\\\n",
    "When the user is setting any goals, help them to rephrase the goal with measurements and ask if that is better. Discard if the user does not like it. \\\n",
    "You can ask the user if they have any monthly or weekly plan and you are helpful on breaking it down to some small daily tasks. \\\n",
    "You are also a helpful assistant that helps users reflect on their emotional patterns and well-being trends. \\\n",
    "You can use available functions to summarize how their week has been or suggest CBT-style tips based on their average emotional state.\\\n",
    "Use summarize_week to summarize mood history. Use suggest_cbt_tip to offer relevant tips grounded in past mood logs. Use describe_emotion_trend to give feedback on how the user's emotional state has evolved over time.\"\"\"\n",
    "\n",
    "def summarize_week() -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the number of journal entries and the emotions recorded over the past 7 days.\n",
    "\n",
    "    Returns:\n",
    "        str: A brief textual summary including number of entries and a list of emotions.\n",
    "    \"\"\"\n",
    "    week_entries = [e for e in journal_entries if datetime.strptime(e['date'], \"%Y-%m-%d\") >= datetime.now() - timedelta(days=7)]\n",
    "    emotions = [e[\"emotion\"] for e in week_entries]\n",
    "    return f\"Entries: {len(week_entries)} | Emotions: {', '.join(emotions)}\"\n",
    "\n",
    "def suggest_cbt_tip() -> str:\n",
    "    \"\"\"\n",
    "    Suggests a CBT-style tip based on recent journal entries using similarity search with RAG documents.\n",
    "\n",
    "    Returns:\n",
    "        str: The most relevant CBT-style tip from the document set or journaling encouragement if insufficient data.\n",
    "    \"\"\"\n",
    "    if not journal_entries:\n",
    "        return \"Try to start journaling consistently.\"\n",
    "    all_entries = [e for e in journal_entries if \"emotion\" in e and e[\"emotion\"]]\n",
    "    if not all_entries:\n",
    "        return \"Reflect on how you're feeling daily to get helpful feedback.\"\n",
    "    query_text = \"Average mood over the past few days has been \" + \", \".join(e[\"emotion\"] for e in all_entries[-5:])\n",
    "    query_embedding = client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents=query_text,\n",
    "        config=types.EmbedContentConfig(task_type=\"retrieval_query\")\n",
    "    ).embeddings[0].values\n",
    "    scores = cosine_similarity([query_embedding], rag_embeddings)[0]\n",
    "    top_index = int(np.argmax(scores))\n",
    "    return RAG_DOCUMENTS[top_index]\n",
    "\n",
    "def describe_emotion_trend() -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the mood trend over time based on emotion scores from journal entries.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether mood has improved, declined, or remained steady.\n",
    "    \"\"\"\n",
    "    if len(journal_entries) < 2:\n",
    "        return \"Not enough entries to assess a trend.\"\n",
    "    scores = [get_emotion_score(e[\"emotion\"]) for e in journal_entries if e.get(\"emotion\")]\n",
    "    if not scores:\n",
    "        return \"No emotion scores available to determine a trend.\"\n",
    "    delta = scores[-1] - scores[0]\n",
    "    if delta > 0:\n",
    "        return \"Your mood seems to be improving over time. ğŸŒ±\"\n",
    "    elif delta < 0:\n",
    "        return \"Your mood seems to have dipped recently. Be kind to yourself. ğŸ’™\"\n",
    "    else:\n",
    "        return \"Your mood has remained steady. ğŸ§˜\"\n",
    "\n",
    "tools = [summarize_week, suggest_cbt_tip, describe_emotion_trend]\n",
    "\n",
    "\n",
    "assistant_chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=tools,\n",
    "        system_instruction=instruction\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707cc7",
   "metadata": {
    "papermill": {
     "duration": 0.045481,
     "end_time": "2025-04-19T20:24:24.442248",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.396767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare functions called by User Interface Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3e803f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:24.535876Z",
     "iopub.status.busy": "2025-04-19T20:24:24.535323Z",
     "iopub.status.idle": "2025-04-19T20:24:24.545251Z",
     "shell.execute_reply": "2025-04-19T20:24:24.544537Z"
    },
    "papermill": {
     "duration": 0.057931,
     "end_time": "2025-04-19T20:24:24.546351",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.488420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "journal_entries: List[Dict] = []\n",
    "\n",
    "def record_in_journal(entry_text: str, emotion_analysis: dict, entry_date: str):\n",
    "    if emotion_analysis is None:\n",
    "        emotion_analysis = analyze_journal_entry(entry_text)\n",
    "\n",
    "    \n",
    "    journal_manager.record_entry(\n",
    "        text=entry_text,\n",
    "        date=entry_date,\n",
    "        emotion_analysis=emotion_analysis,\n",
    "        tags=emotion_analysis['themes'],\n",
    "        category=\"daily\"\n",
    "    )\n",
    "\n",
    "    journal_entries.append({\n",
    "        \"date\": entry_date,\n",
    "        \"entry\": entry_text,\n",
    "        **emotion_analysis\n",
    "    })\n",
    "\n",
    "def analyze_and_display(entry_text: str, entry_date: str) -> str:\n",
    "    result = analyze_journal_entry(entry_text)\n",
    "\n",
    "    record_in_journal(entry_text, result, entry_date)\n",
    "    \n",
    "    return f\"\"\"\n",
    "**Emotion:** {result['emotion']}\n",
    "\n",
    "**Themes:** {', '.join(result['themes'])}\n",
    "\n",
    "**Reflection Suggestion:** {result['suggestion']}\n",
    "\n",
    "**Daily Affirmation:** {result['affirmation']}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def chatbot_reply(message, history):\n",
    "    response = assistant_chat.send_message(message)\n",
    "\n",
    "    output = history + [[message, response.text]]\n",
    "    \n",
    "    record_in_journal(str(output), None, datetime.now())\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_and_show_journal_records() -> str:\n",
    "    \"\"\"\n",
    "    Get all journal entries formatted as a markdown string.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted markdown string containing all journal entries\n",
    "    \"\"\"\n",
    "    entries = journal_manager.get_all_entries()\n",
    "    markdown = []\n",
    "    \n",
    "    for entry in entries:\n",
    "        # Entry header with date and category\n",
    "        markdown.append(f\"## {entry['date']} - {entry['category'].title()}\")\n",
    "        markdown.append(\"\")\n",
    "        \n",
    "        # Main content\n",
    "        markdown.append(f\"{entry['content']['text']}\")\n",
    "        markdown.append(\"\")\n",
    "        \n",
    "        # Tasks section\n",
    "        if entry['content']['tasks']:\n",
    "            markdown.append(\"### Tasks\")\n",
    "            for task in entry['content']['tasks']:\n",
    "                status = \"âœ…\" if task['status'] == \"done\" else \"â³\"\n",
    "                markdown.append(f\"- {status} {task['task']} (Priority: {task['priority']})\")\n",
    "            markdown.append(\"\")\n",
    "        \n",
    "        # Goals section\n",
    "        if entry['content']['goals']:\n",
    "            markdown.append(\"### Goals\")\n",
    "            for goal in entry['content']['goals']:\n",
    "                progress = goal['progress']\n",
    "                progress_bar = \"â–ˆ\" * (progress // 10) + \"â–‘\" * (10 - progress // 10)\n",
    "                markdown.append(f\"- {goal['goal']} ({goal['timeframe']})\")\n",
    "                markdown.append(f\"  Progress: {progress}% [{progress_bar}]\")\n",
    "            markdown.append(\"\")\n",
    "        \n",
    "        # Emotion analysis\n",
    "        if entry['emotion_analysis']:\n",
    "            markdown.append(\"### Emotional State\")\n",
    "            markdown.append(f\"{entry['emotion_analysis']}\")\n",
    "            markdown.append(\"\")\n",
    "        \n",
    "        # Tags\n",
    "        if entry['content']['tags']:\n",
    "            markdown.append(\"### Tags\")\n",
    "            markdown.append(\", \".join(f\"`{tag}`\" for tag in entry['content']['tags']))\n",
    "            markdown.append(\"\")\n",
    "        \n",
    "        # Metadata\n",
    "        markdown.append(\"---\")\n",
    "        markdown.append(f\"*Last modified: {entry['metadata']['last_modified']}*\")\n",
    "        markdown.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(markdown) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234d81c",
   "metadata": {
    "papermill": {
     "duration": 0.045852,
     "end_time": "2025-04-19T20:24:24.638466",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.592614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Gradio User Interface\n",
    "\n",
    "The following part create a front-end user interactive page that allows users to input their notes, see the past trends, and interact with chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82783706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:24.735564Z",
     "iopub.status.busy": "2025-04-19T20:24:24.734975Z",
     "iopub.status.idle": "2025-04-19T20:24:24.928460Z",
     "shell.execute_reply": "2025-04-19T20:24:24.927619Z"
    },
    "papermill": {
     "duration": 0.245224,
     "end_time": "2025-04-19T20:24:24.930055",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.684831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ğŸª¶ BujoNow: Multimodal Journal Tracker\")\n",
    "    date_input = Calendar(label=\"Entry Date\")\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## âœğŸ¼ Your Journaling\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "\n",
    "            with gr.Tab(\"ğŸ’¬ BujoNow Assistant\"):\n",
    "                gr.Markdown(\"## ğŸ’¬ BujoNow Assistant\")\n",
    "                chatbot = gr.Chatbot()\n",
    "                chat_input = gr.Textbox(placeholder=\"Help me plan my day...\")\n",
    "                send_btn = gr.Button(\"Send\")\n",
    "                send_btn.click(fn=chatbot_reply, inputs=[chat_input, chatbot], outputs=chatbot)\n",
    "                chat_input.submit(fn=chatbot_reply, inputs=[chat_input, chatbot], outputs=chatbot)\n",
    "\n",
    "            \n",
    "            with gr.Tab(\"ğŸ“ Text Entry\"):\n",
    "                entry_input = gr.Textbox(\n",
    "                    lines=6,\n",
    "                    label=\"Journal Entry\",\n",
    "                    # value=\"For example: Iâ€™ve been feeling overwhelmed with work and donâ€™t have time to relax.\",\n",
    "                    placeholder=\"Write your journal entry here...\"\n",
    "                )\n",
    "        \n",
    "                text_analysis = gr.Markdown()\n",
    "                analyze_text_btn = gr.Button(\"Record\")\n",
    "        \n",
    "                analyze_text_btn.click(analyze_and_display, inputs=[entry_input, date_input], outputs=text_analysis)\n",
    "    \n",
    "            with gr.Tab(\"ğŸ¤ Audio Entry\"):\n",
    "                audio_input = gr.Audio(sources=[\"upload\", \"microphone\"], type=\"filepath\")\n",
    "                audio_transcript = gr.Textbox(label=\"Transcript\")\n",
    "                audio_analysis = gr.Markdown()\n",
    "                transcribe_btn = gr.Button(\"Transcribe + Analyze\")\n",
    "                transcribe_btn.click(recognize_audio, inputs=audio_input, outputs=audio_transcript).then(\n",
    "                    analyze_and_display, inputs=[audio_transcript, date_input], outputs=audio_analysis\n",
    "                )\n",
    "\n",
    "            with gr.Tab(\"ğŸ“¸ Image Entry\"):\n",
    "                image_input = gr.Image(type=\"pil\")\n",
    "                image_result = gr.Textbox(label=\"Detected Emotion\")\n",
    "                analyze_image_btn = gr.Button(\"Detect and Add\")\n",
    "\n",
    "                def detect_and_store_image(img, date_str):\n",
    "                    emotion = detect_emotion_from_image(img)\n",
    "                    journal_entries.append({\n",
    "                        \"date\": date_str,\n",
    "                        \"entry\": \"Image mood analysis\",\n",
    "                        \"emotion\": emotion,\n",
    "                        \"themes\": [],\n",
    "                        \"suggestion\": \"\",\n",
    "                        \"affirmation\": \"\"\n",
    "                    })\n",
    "                    return emotion\n",
    "\n",
    "                analyze_image_btn.click(detect_and_store_image, inputs=[image_input, date_input], outputs=image_result)\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"## My Past Journals\")\n",
    "            show_record_btn = gr.Button(\"Show My Journal\")\n",
    "            journal_output = gr.Markdown()\n",
    "            show_record_btn.click(get_and_show_journal_records, outputs=journal_output)\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Summarize My Journals\")\n",
    "    with gr.Row(\"ğŸ“ˆ Mood Visualizations\"):\n",
    "        with gr.Row():\n",
    "            trend_btn = gr.Button(\"ğŸ“ˆ Mood Trend\")\n",
    "            dist_btn = gr.Button(\"ğŸ“Š Emotion Distribution\")\n",
    "            cloud_btn = gr.Button(\"â˜ï¸ Word Cloud\")\n",
    "        viz_plot = gr.Plot()\n",
    "        trend_btn.click(fn=plot_trend_wrapper, outputs=viz_plot)\n",
    "        dist_btn.click(lambda: plot_emotion_distribution(journal_entries), outputs=viz_plot)\n",
    "        cloud_btn.click(lambda: plot_wordcloud(journal_entries), outputs=viz_plot)\n",
    "        \n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Suggestions & Reflections\")\n",
    "    with gr.Row():\n",
    "        with gr.Row():\n",
    "            goal_input = gr.Textbox(label=\"â¯ Input Your Goal Here\", placeholder=\"e.g., calm, joyful\")\n",
    "        with gr.Row():\n",
    "            goal_btn = gr.Button(\"ğŸ¯ Suggest Tip Toward Goal\")\n",
    "            goal_output = gr.Textbox(label=\"Suggestion and Affirmation\")\n",
    "            goal_btn.click(suggest_tip_toward_goal, inputs=goal_input, outputs=goal_output)\n",
    "            \n",
    "        with gr.Row():\n",
    "            reflect_btn = gr.Button(\"ğŸ§˜ Weekly Reflection Summary\")\n",
    "            reflect_output = gr.Textbox(label=\"Reflection Summary\")\n",
    "            reflect_btn.click(lambda: reflect_on_week(journal_entries), outputs=reflect_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e178473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T20:24:25.027104Z",
     "iopub.status.busy": "2025-04-19T20:24:25.026325Z",
     "iopub.status.idle": "2025-04-19T20:24:25.892160Z",
     "shell.execute_reply": "2025-04-19T20:24:25.891560Z"
    },
    "papermill": {
     "duration": 0.91402,
     "end_time": "2025-04-19T20:24:25.893253",
     "exception": false,
     "start_time": "2025-04-19T20:24:24.979233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://7f38c702274a5dd6ae.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7f38c702274a5dd6ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1929b9c",
   "metadata": {
    "papermill": {
     "duration": 0.049016,
     "end_time": "2025-04-19T20:24:25.990532",
     "exception": false,
     "start_time": "2025-04-19T20:24:25.941516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 97258,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 267.484268,
   "end_time": "2025-04-19T20:24:31.256113",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-19T20:20:03.771845",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
